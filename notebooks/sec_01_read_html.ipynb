{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in HTMLs of SEC Filings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "import itertools\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import re\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create function to extract stock from filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stock(string, filepath = True):\n",
    "    if filepath:\n",
    "        return re.search(r'data\\\\([a-z]+)[-\\d_]',string).group(1)\n",
    "    else:\n",
    "        return re.search(r'^([a-z]+)[-\\d_]',string).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make soups dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "soups = {extract_stock(filepath): BS(open(filepath), 'html.parser') for filepath in glob.glob('../data/*.htm*')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create text-creation function and texts dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    " def make_text(stock):\n",
    "    text_list = [tag.get_text().strip() for tag in soups[stock].find_all(['div', 'p'])]\n",
    "    text = '\\n'.join(text_list).replace('\\xa0', ' ').replace('  ', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_dict = {stock: make_text(stock) for stock in soups.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = texts_dict.values()\n",
    "stocks = texts_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['amrk', 'apog', 'azz', 'bbw', 'cnxc', 'ctrn', 'earn', 'fnhc', 'ful', 'gwre', 'info', 'intc', 'kbh', 'kmx', 'lake', 'lvis', 'mcft', 'mdc', 'mtn', 'nflx', 'noc', 'panw', 'prgs', 'pstg', 'siri', 'slb', 'tlys', 'tmb', 'uri', 'vrrm'])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = json.load(open('../data/annotations.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'azz-20220228.html'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[0]['filing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dict = {}\n",
    "for entry in annotations:\n",
    "    stock = extract_stock(entry['filing'], filepath=False)\n",
    "    text = entry['text']\n",
    "    if stock in extract_dict.keys():\n",
    "        extract_dict[stock][text] = {key:value for key, value in entry.items() if key not in ['filing', 'text']}\n",
    "    else:\n",
    "        extract_dict[stock] = {}\n",
    "        extract_dict[stock][text] = {key:value for key, value in entry.items() if key not in ['filing', 'text']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the first quarter of 2021, we repurchased the remaining $2.4 billion in shares of our planned $20.0 billion share repurchases announced in October 2019. We expect our future stock repurchases to be significantly below our levels from the last few years.'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(extract_dict['intc'].keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate spacy model, documentize texts, and add metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create training tuples for each 10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['azz', 'apog', 'fnhc', 'vrrm', 'bbw', 'cnxc', 'ctrn', 'earn', 'info', 'kmx', 'lake', 'mdc', 'noc', 'prgs', 'kbh', 'pstg', 'siri', 'tlys', 'tmb', 'uri', 'lvis', 'nflx', 'slb', 'ful', 'intc', 'mcft', 'mtn', 'panw', 'amrk', 'gwre'])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the keys\n",
    "extract_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with a test case (azz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"On November 10, 2020, the Company's Board of Directors authorized a $100 million share repurchase program pursuant to which the Company may repurchase its common stock (the “2020 Authorization”). Repurchases under the 2020 Authorization will be made through open market and/or private transactions, in accordance with applicable federal securities laws, and could include repurchases pursuant to Rule 10b5-1 trading plans, which allows stock repurchases when the Company might otherwise be precluded from doing so.\",\n",
       " 'The Company purchased 601,822 of its common shares in the amount of $30.8 million at an average purchase price of $51.20 under the 2020 Authorization during fiscal 2022.']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use azz as a test case for labeling\n",
    "list(extract_dict.get('azz').keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Company purchased 601,822 of its common shares in the amount of $30.8 million at an average purchase price of $51.20 under the 2020 Authorization during fiscal 2022.'"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize by text bounded by line breaks\n",
    "azz_tok = regexp_tokenize(texts_dict['azz'], r'[^\\n]+')\n",
    "\n",
    "# find which tokens are equal to our annotations\n",
    "azz_annotation_text = 1\n",
    "azz_annot_index = [tok == list(extract_dict.get('azz').keys())[azz_annotation_text] for tok in azz_tok].index(True)\n",
    "azz_tok[azz_annot_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that exactly two tokens match our annotations for azz\n",
    "[tok in list(extract_dict.get('azz').keys()) for tok in azz_tok]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dictionaries containing the labels (True or False) for each \"paragraph\" of each 10k\n",
    "- True corresponds to a repurchase-related paragraph and False corresponds to an irrelevant paragraph.\n",
    "- labels_dict has the stock as keys and the texts and labels as tuples\n",
    "- labels_dict_for_df has the same information but prepared for dataframe conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {stock: (token, label)}\n",
    "labels_dict = {key: [(tok, tok in list(extract_dict.get(key).keys())) for tok in regexp_tokenize(texts_dict[key], r'[^\\n]+')] for key in texts_dict.keys()}\n",
    "\n",
    "# {stock: {'token': tokens_list, 'label': labels_list}}\n",
    "labels_dict_for_df = {key: {'token': [tok for tok in regexp_tokenize(texts_dict[key], r'[^\\n]+')], \n",
    "                            'label': [tok in list(extract_dict.get(key).keys()) for tok in regexp_tokenize(texts_dict[key], r'[^\\n]+')]} \n",
    "                      for key in texts_dict.keys()\n",
    "                      }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the labels dataframe and use sklearn to train_test_split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.concat({key: pd.DataFrame.from_dict(value) for key, value in labels_dict_for_df.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from spacy.pipeline.textcat import DEFAULT_SINGLE_TEXTCAT_MODEL\n",
    "import classy_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = labels_df['token']\n",
    "y = labels_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fnhc  1578     In December 2019, the Company's Board of Direc...\n",
       "vrrm  11371    On August 9, 2021, the Company announced that ...\n",
       "mdc   674      At December 31, 2021, we were authorized to re...\n",
       "bbw   828      We ended fiscal 2021 with no borrowings under ...\n",
       "cnxc  546      In September 2021, our board of directors auth...\n",
       "info  1227     During the years ended November 30, 2020 and 2...\n",
       "ctrn  1381     During fiscal 2021 and 2020, we returned $115....\n",
       "Name: token, dtype: object"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying that the df works as expected\n",
    "X_test[y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build first model off of base spacy small (with help from classy)\n",
    "This model never predicts repurchase (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'repurchase': X_train[y_train == True].values.tolist(),\n",
    "        'irrelevant': X_train[y_train == False].values.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<classy_classification.classifiers.spacy_internal.classySpacyInternal at 0x1435a4f9520>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"text_categorizer\",\n",
    "              config = {\"model\": 'spacy',\n",
    "                        \"data\": data\n",
    "                      }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [nlp(test_tok)._.cats for test_tok in X_test.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_summary = [pred['repurchase'] > 0.5 for pred in preds]\n",
    "preds_repur = [pred['repurchase'] for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16103, 0.19159251223724055),\n",
       " (1294, 0.06239400916238595),\n",
       " (20462, 0.06129394065852936),\n",
       " (19452, 0.05920115414171221),\n",
       " (30384, 0.05449088135414002),\n",
       " (19580, 0.0520140554850948),\n",
       " (26721, 0.05004572590881312),\n",
       " (4894, 0.04695912011592231),\n",
       " (14323, 0.04020289978825083),\n",
       " (20793, 0.03301462391344541)]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(enumerate(preds_repur), key = lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's a failed attempt at implementing this with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://huggingface.co/api/models/%20sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-327-6a5a93396bf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"en\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m nlp.add_pipe(\"text_categorizer\",\n\u001b[0m\u001b[0;32m      3\u001b[0m               config = {\"model\": ' sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n\u001b[0;32m      4\u001b[0m                         \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[1;34m\"device\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    790\u001b[0m                     \u001b[0mlang_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 )\n\u001b[1;32m--> 792\u001b[1;33m             pipe_component = self.create_pipe(\n\u001b[0m\u001b[0;32m    793\u001b[0m                 \u001b[0mfactory_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mcreate_pipe\u001b[1;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;31m# We're calling the internal _fill here to avoid constructing the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[1;31m# registered functions twice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mresolved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"cfg\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"cfg\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\config.py\u001b[0m in \u001b[0;36mresolve\u001b[1;34m(cls, config, schema, overrides, validate)\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m     ) -> Dict[str, Any]:\n\u001b[1;32m--> 746\u001b[1;33m         resolved, _ = cls._make(\n\u001b[0m\u001b[0;32m    747\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresolve\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\config.py\u001b[0m in \u001b[0;36m_make\u001b[1;34m(cls, config, schema, overrides, resolve, validate)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_interpolated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m         filled, _, resolved = cls._fill(\n\u001b[0m\u001b[0;32m    796\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresolve\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\config.py\u001b[0m in \u001b[0;36m_fill\u001b[1;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[0;32m    865\u001b[0m                     \u001b[1;31m# We don't want to try/except this and raise our own error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m                     \u001b[1;31m# here, because we want the traceback if the function fails.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m                     \u001b[0mgetter_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[1;31m# We're not resolving and calling the function, so replace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\classy_classification\\__init__.py\u001b[0m in \u001b[0;36mmake_text_categorizer\u001b[1;34m(nlp, name, data, device, config, model, cat_type, include_doc, include_sent)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                 return classySpacyFewShotExternal(\n\u001b[0m\u001b[0;32m     69\u001b[0m                     \u001b[0mnlp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\classy_classification\\classifiers\\spacy_few_shot_external.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, nlp, name, data, device, config, include_doc, include_sent, *args, **kwargs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mclassySpacyFewShotExternal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassySentenceTransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_sent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minclude_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minclude_doc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\classy_classification\\classifiers\\sentence_transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, model, device, config)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_embedding_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_training_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_svc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\classy_classification\\classifiers\\sentence_transformer.py\u001b[0m in \u001b[0;36mset_embedding_model\u001b[1;34m(self, model, device)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update if overwritten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;31m# Download from hub with caching\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                 snapshot_download(model_name_or_path,\n\u001b[0m\u001b[0;32m     87\u001b[0m                                     \u001b[0mcache_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                                     \u001b[0mlibrary_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sentence-transformers'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sentence_transformers\\util.py\u001b[0m in \u001b[0;36msnapshot_download\u001b[1;34m(repo_id, revision, cache_dir, library_name, library_version, user_agent, ignore_files, use_auth_token)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[0m_api\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m     \u001b[0mmodel_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m     storage_folder = os.path.join(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             args_msg = [\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\huggingface_hub\\hf_api.py\u001b[0m in \u001b[0;36mmodel_info\u001b[1;34m(self, repo_id, revision, token, timeout, securityStatus)\u001b[0m\n\u001b[0;32m   1119\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstatus_query_param\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m         )\n\u001b[1;32m-> 1121\u001b[1;33m         \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mModelInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 943\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/api/models/%20sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"text_categorizer\",\n",
    "              config = {\"model\": ' sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "                        \"data\": data,\n",
    "                        \"device\": \"cpu\",\n",
    "                        \n",
    "                      }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's a successful attempt at implementing this with BERT's Q&A model\n",
    "Note, there's no training here, so this is essentially a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "query_embedding = model.encode('Are there repurchases')\n",
    "passage_embedding = model.encode(X_test.values.tolist())\n",
    "\n",
    "bert_test_scores = util.dot_score(query_embedding, passage_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12930, 0.7698134),\n",
       " (28849, 0.74283355),\n",
       " (2765, 0.7428335),\n",
       " (4720, 0.7428335),\n",
       " (10357, 0.7428335),\n",
       " (25149, 0.70291966),\n",
       " (17106, 0.7006395),\n",
       " (3128, 0.69797015),\n",
       " (13357, 0.68717366),\n",
       " (1843, 0.6508532),\n",
       " (20597, 0.6508532),\n",
       " (21475, 0.6508532),\n",
       " (22824, 0.6506263),\n",
       " (17033, 0.6450168),\n",
       " (11819, 0.64463985),\n",
       " (2389, 0.6433725),\n",
       " (3268, 0.6433725),\n",
       " (10127, 0.6433725),\n",
       " (14323, 0.6414058),\n",
       " (7140, 0.6253795)]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(enumerate(bert_test_scores.numpy()[0]), key = lambda x: x[1], reverse=True)[0:20]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91809cd6930bcd5c93f1baaa8e75dc4fbfa15bbd921b33b01843a7cf2fa05e32"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
